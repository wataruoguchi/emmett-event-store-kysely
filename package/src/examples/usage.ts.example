// Example usage following Emmett's patterns
// This shows how to use the Kysely EventStore similar to @event-driven-io/emmett-postgresql

import { Kysely, PostgresDialect } from "kysely";
import { Pool } from "pg";
import {
  getKyselyEventStore,
  createKyselyEventStoreConsumer,
  createEventStore,
} from "../event-store/index.js";
import type { Logger } from "../types.js";

// Example database schema
interface Database {
  streams: {
    stream_id: string;
    stream_position: bigint;
    partition: string;
    stream_type: string;
    stream_metadata: Record<string, unknown>;
    is_archived: boolean;
    created_at: Date;
    updated_at: Date;
  };
  messages: {
    global_position: bigint;
    stream_id: string;
    stream_position: bigint;
    partition: string;
    message_type: string;
    message_data: unknown;
    message_metadata: Record<string, unknown>;
    message_schema_version: string;
    message_kind: string;
    message_id: string;
    is_archived: boolean;
    created: Date;
  };
  subscriptions: {
    consumer_name: string;
    last_processed_position: bigint;
    last_processed_transaction_id: bigint;
    created_at: Date;
    updated_at: Date;
  };
}

/**
 * Example 1: Using Emmett-style API (Recommended)
 * This approach follows @event-driven-io/emmett-postgresql patterns
 */
export async function exampleEmmettStyle() {
  // Set up database connection (similar to Emmett's pattern)
  const connectionString =
    process.env.DATABASE_URL ??
    "postgresql://postgres:postgres@localhost:5432/postgres";

  const db = new Kysely<Database>({
    dialect: new PostgresDialect({
      pool: new Pool({
        connectionString,
      }),
    }),
  });

  const logger: Logger = {
    info: (obj, msg) => console.log(msg, obj),
    error: (obj, msg) => console.error(msg, obj),
    warn: (obj, msg) => console.warn(msg, obj),
    debug: (obj, msg) => console.debug(msg, obj),
  };

  // Create event store using getKyselyEventStore (similar to getPostgreSQLEventStore)
  const eventStore = getKyselyEventStore({ db, logger });

  // Example: Append events to a stream
  const result = await eventStore.appendToStream(
    "cart-123",
    [
      {
        type: "CartCreated",
        data: { cartId: "cart-123", currency: "USD" },
      },
      {
        type: "ItemAdded",
        data: { cartId: "cart-123", itemId: "item-1", quantity: 2 },
      },
    ],
    {
      partition: "tenant-1",
      streamType: "cart",
    },
  );

  console.log("Append result:", result);

  // Example: Read events from a stream
  const events = await eventStore.readStream("cart-123", {
    partition: "tenant-1",
  });

  console.log("Read events:", events);

  // Example: Aggregate stream
  const aggregateResult = await eventStore.aggregateStream("cart-123", {
    evolve: (state, event) => {
      // Your domain logic here
      return { ...state, lastEvent: event.type };
    },
    initialState: () => ({ lastEvent: null }),
    read: { partition: "tenant-1" },
  });

  console.log("Aggregate result:", aggregateResult);

  // Example: Create consumer for event processing
  const consumer = createKyselyEventStoreConsumer({
    db,
    logger,
    consumerName: "cart-processor",
    batchSize: 50,
    pollingInterval: 1000,
  });

  // Subscribe to specific event types
  consumer.subscribe((event) => {
    console.log("Processing cart event:", event);
  }, "CartCreated");

  consumer.subscribe((event) => {
    console.log("Processing item event:", event);
  }, "ItemAdded");

  // Subscribe to all events
  consumer.subscribeToAll((event) => {
    console.log("Processing any event:", event);
  });

  // Start consuming events
  await consumer.start();

  // Clean up
  await consumer.stop();
  await eventStore.close();
}

/**
 * Example 2: Using Legacy API (Backward Compatibility)
 * This approach uses the original createEventStore function
 */
export async function exampleLegacyStyle() {
  const connectionString =
    process.env.DATABASE_URL ??
    "postgresql://postgres:postgres@localhost:5432/postgres";

  const db = new Kysely<Database>({
    dialect: new PostgresDialect({
      pool: new Pool({ connectionString }),
    }),
  });

  const logger: Logger = {
    info: (obj, msg) => console.log(msg, obj),
    error: (obj, msg) => console.error(msg, obj),
  };

  // Create event store using legacy createEventStore function
  const { readStream, appendToStream, aggregateStream } = createEventStore({
    db,
    logger,
  });

  // Example: Append events using the legacy function
  const result = await appendToStream(
    "cart-456",
    [
      {
        type: "CartCreated",
        data: { cartId: "cart-456", currency: "EUR" },
      },
    ],
    {
      partition: "tenant-2",
      streamType: "cart",
    },
  );

  console.log("Append result:", result);

  // Example: Read events using the legacy function
  const events = await readStream("cart-456", {
    partition: "tenant-2",
  });

  console.log("Read events:", events);

  // Example: Aggregate stream using the legacy function
  const aggregateResult = await aggregateStream("cart-456", {
    evolve: (state, event) => {
      return { ...state, lastEvent: event.type };
    },
    initialState: () => ({ lastEvent: null }),
    read: { partition: "tenant-2" },
  });

  console.log("Aggregate result:", aggregateResult);
}

/**
 * Example 3: Working with Emmett's DeciderCommandHandler
 * This shows how to integrate with Emmett's command handling
 */
export async function exampleWithDeciderHandler() {
  const connectionString =
    process.env.DATABASE_URL ??
    "postgresql://postgres:postgres@localhost:5432/postgres";

  const db = new Kysely<Database>({
    dialect: new PostgresDialect({
      pool: new Pool({ connectionString }),
    }),
  });

  const logger: Logger = {
    info: (obj, msg) => console.log(msg, obj),
    error: (obj, msg) => console.error(msg, obj),
  };

  // Create event store
  const eventStore = getKyselyEventStore({ db, logger });

  // Example domain types
  type CartCommand =
    | { type: "CreateCart"; data: { cartId: string; currency: string } }
    | { type: "AddItem"; data: { cartId: string; itemId: string; quantity: number } };

  type CartEvent =
    | { type: "CartCreated"; data: { cartId: string; currency: string } }
    | { type: "ItemAdded"; data: { cartId: string; itemId: string; quantity: number } };

  type CartState = {
    cartId?: string;
    currency?: string;
    items: Array<{ itemId: string; quantity: number }>;
  };

  // Define your decider functions
  const decide = (state: CartState, command: CartCommand): CartEvent[] => {
    switch (command.type) {
      case "CreateCart":
        if (state.cartId) {
          throw new Error("Cart already exists");
        }
        return [{ type: "CartCreated", data: command.data }];
      case "AddItem":
        if (!state.cartId) {
          throw new Error("Cart does not exist");
        }
        return [{ type: "ItemAdded", data: command.data }];
    }
  };

  const evolve = (state: CartState, event: CartEvent): CartState => {
    switch (event.type) {
      case "CartCreated":
        return {
          ...state,
          cartId: event.data.cartId,
          currency: event.data.currency,
        };
      case "ItemAdded":
        return {
          ...state,
          items: [...state.items, { itemId: event.data.itemId, quantity: event.data.quantity }],
        };
    }
  };

  const initialState = (): CartState => ({
    items: [],
  });

  // Use with Emmett's DeciderCommandHandler pattern
  // Note: You would typically use @event-driven-io/emmett's DeciderCommandHandler here
  const streamId = "cart-789";
  const command: CartCommand = {
    type: "CreateCart",
    data: { cartId: streamId, currency: "GBP" },
  };

  // Get current state
  const { state } = await eventStore.aggregateStream(streamId, {
    evolve,
    initialState,
    read: { partition: "tenant-3" },
  });

  // Decide what events to emit
  const events = decide(state, command);

  // Append the events
  await eventStore.appendToStream(streamId, events, {
    partition: "tenant-3",
    streamType: "cart",
  });

  console.log("Command processed successfully");
}

/**
 * Example 4: Consumer with Error Handling
 * This shows advanced consumer patterns
 */
export async function exampleConsumerWithErrorHandling() {
  const connectionString =
    process.env.DATABASE_URL ??
    "postgresql://postgres:postgres@localhost:5432/postgres";

  const db = new Kysely<Database>({
    dialect: new PostgresDialect({
      pool: new Pool({ connectionString }),
    }),
  });

  const logger: Logger = {
    info: (obj, msg) => console.log(msg, obj),
    error: (obj, msg) => console.error(msg, obj),
  };

  // Create consumer with custom configuration
  const consumer = createKyselyEventStoreConsumer({
    db,
    logger,
    consumerName: "error-handling-consumer",
    batchSize: 10, // Process 10 events at a time
    pollingInterval: 2000, // Poll every 2 seconds
  });

  // Subscribe with error handling
  consumer.subscribe(async (event) => {
    try {
      // Process the event
      console.log("Processing CartCreated:", event);
      
      // Your business logic here
      // e.g., update read model, send notification, etc.
      
    } catch (error) {
      // Handle errors gracefully
      console.error("Failed to process CartCreated:", error);
      // Note: The consumer will continue processing other events
    }
  }, "CartCreated");

  // Subscribe to multiple event types
  consumer.subscribe(async (event) => {
    console.log("Processing ItemAdded:", event);
  }, "ItemAdded");

  // Subscribe to all events for logging
  consumer.subscribeToAll((event) => {
    console.log(`Event received: ${event.type} at position ${event.metadata.globalPosition}`);
  });

  // Start the consumer
  await consumer.start();

  // The consumer will run until you stop it
  // In a real application, you'd keep this running
  // For this example, we'll stop after a delay
  await new Promise((resolve) => setTimeout(resolve, 10000));
  
  await consumer.stop();
  console.log("Consumer stopped");
}
